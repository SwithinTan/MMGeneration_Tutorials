{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6a673c-9cb1-4ca6-82b2-05cdeab6dba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6adf0fa3-24ae-4145-adf7-0d3a0c09bbbe",
   "metadata": {},
   "source": [
    "## 进入MMGeneration主目录¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b840a387-f43f-44fe-99cc-00e50e7e1b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.dev_scripts',\n",
       " '.github',\n",
       " '.gitignore',\n",
       " '.pre-commit-config.yaml',\n",
       " '.pylintrc',\n",
       " '.readthedocs.yml',\n",
       " 'CITATION.cff',\n",
       " 'LICENSE',\n",
       " 'LICENSES.md',\n",
       " 'MANIFEST.in',\n",
       " 'README.md',\n",
       " 'README_zh-CN.md',\n",
       " 'apps',\n",
       " 'configs',\n",
       " 'demo',\n",
       " 'docker',\n",
       " 'docs',\n",
       " 'mmgen',\n",
       " 'model-index.yml',\n",
       " 'requirements.txt',\n",
       " 'requirements',\n",
       " 'setup.cfg',\n",
       " 'setup.py',\n",
       " 'tests',\n",
       " 'tools',\n",
       " 'mmgen.egg-info',\n",
       " 'outputs',\n",
       " 'data',\n",
       " 'checkpoints',\n",
       " 'work_dirs']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('mmgeneration')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ba49e8-7e32-4f6e-93bb-c966f2ce3c95",
   "metadata": {},
   "source": [
    "## 头发颜色修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9812cb2f-51ed-4d54-aa9e-c2df55ab8443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-10 16:52:13--  https://download.openmmlab.com/mmgen/stylegan2/stylegan2_c2_ffhq_256_b4x8_20210407_160709-7890ae1f.pth\n",
      "Connecting to 172.16.0.13:5848... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 357247352 (341M) [application/zip]\n",
      "Saving to: ‘checkpoints/stylegan2_c2_ffhq_256_b4x8_20210407_160709-7890ae1f.pth’\n",
      "\n",
      "checkpoints/stylega 100%[===================>] 340.70M  91.1MB/s    in 3.8s    \n",
      "\n",
      "2022-04-10 16:52:16 (90.3 MB/s) - ‘checkpoints/stylegan2_c2_ffhq_256_b4x8_20210407_160709-7890ae1f.pth’ saved [357247352/357247352]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 下载模型权重文件\n",
    "!wget https://download.openmmlab.com/mmgen/stylegan2/stylegan2_c2_ffhq_256_b4x8_20210407_160709-7890ae1f.pth -O checkpoints/stylegan2_c2_ffhq_256_b4x8_20210407_160709-7890ae1f.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeefcdcb-46b3-436c-b8d4-c524b02e0e79",
   "metadata": {},
   "source": [
    "i = 15 头发颜色\n",
    "d 变化程度\n",
    "l 修改前几层的latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e27aa05-aa6b-4577-a21c-a4487a7b376d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-10 16:52:46,632 - mmgen - INFO - Building models and loading checkpoints\n",
      "2022-04-10 16:52:47,660 - mmgen - INFO - Switch to evaluation style mode: single\n",
      "2022-04-10 16:52:47,661 - mmgen - INFO - Switch to evaluation style mode: single\n",
      "load checkpoint from local path: checkpoints/stylegan2_c2_ffhq_256_b4x8_20210407_160709-7890ae1f.pth\n",
      "2022-04-10 16:53:00,564 - mmgen - INFO - Calculating or loading eigen vectors\n",
      "2022-04-10 16:53:00,622 - mmgen - INFO - Sampling images with modified SeFa\n",
      "/environment/miniconda3/lib/python3.7/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "2022-04-10 16:53:06,221 - mmgen - INFO - Save images to ./work_dirs/sefa-exp//entangle-i15-d[8.0]-t0.5-l[8, 9]_000020.png\n"
     ]
    }
   ],
   "source": [
    "!python apps/modified_sefa.py \\\n",
    "    --config configs/styleganv2/stylegan2_c2_ffhq_256_b4x8_800k.py \\\n",
    "    --ckpt checkpoints/stylegan2_c2_ffhq_256_b4x8_20210407_160709-7890ae1f.pth \\\n",
    "    -i 15 -d 8. --degree-step 0.5 -l 8 9 --sample-path ./work_dirs/sefa-exp/ \\\n",
    "    --sample-cfg randomize_noise=False --random-seed 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3a91be-e12a-4ec4-adf9-abfbf0c80e5c",
   "metadata": {},
   "source": [
    "## 中间脸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73ef236f-22d3-4aa4-8504-7c03f3dfbdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set random seed to 2021\n",
      "load checkpoint from local path: checkpoints/stylegan2_c2_ffhq_256_b4x8_20210407_160709-7890ae1f.pth\n",
      "2022-04-04 17:22:27,093 - mmgen - INFO - Sampling model: ema\n",
      "2022-04-04 17:22:27,093 - mmgen - INFO - Switch to evaluation style mode: single\n",
      "Setting up Perceptual loss...\n",
      "...[pnet-lin, vgg16] initializing\n",
      "Loading model from: https://download.openmmlab.com/mmgen/evaluation/lpips/weights/v0.1/vgg.pth\n",
      "...Done\n",
      " perceptual: 0.4162, noise regularize:0.0000, mse: 0.0526, lr: 0.0000: 100%|█| 1\n"
     ]
    }
   ],
   "source": [
    "!python apps/stylegan_projector.py \\\n",
    "        configs/styleganv2/stylegan2_c2_ffhq_256_b4x8_800k.py \\\n",
    "        checkpoints/stylegan2_c2_ffhq_256_b4x8_20210407_160709-7890ae1f.pth \\\n",
    "        demo/wyf-head.png \\\n",
    "        demo/zzh-head.png \\\n",
    "        --total-iters 2000 \\\n",
    "        --results-path work_dirs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7d6f9b-989d-4244-aea9-de3f240476d2",
   "metadata": {},
   "source": [
    "## 通过文字描述，生成图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7fc7291-adea-4eeb-affa-917deb396918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-zjphclwe\n",
      "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-zjphclwe\n",
      "Collecting ftfy\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e1/1e/bf736f9576a8979752b826b75cbd83663ff86634ea3055a766e2d8ad3ee5/ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 27.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e0/93/f1d8fa622a3c40c55ae4edcaabf8620438b86c7e70900ea2ed88aa51afd8/regex-2022.3.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
      "\u001b[K     |████████████████████████████████| 749 kB 69.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /environment/miniconda3/lib/python3.7/site-packages (from clip==1.0) (4.61.2)\n",
      "Requirement already satisfied: torch in /environment/miniconda3/lib/python3.7/site-packages (from clip==1.0) (1.10.1+cu113)\n",
      "Requirement already satisfied: torchvision in /environment/miniconda3/lib/python3.7/site-packages (from clip==1.0) (0.11.2+cu113)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /environment/miniconda3/lib/python3.7/site-packages (from ftfy->clip==1.0) (0.2.5)\n",
      "Requirement already satisfied: typing-extensions in /environment/miniconda3/lib/python3.7/site-packages (from torch->clip==1.0) (4.0.1)\n",
      "Requirement already satisfied: numpy in /environment/miniconda3/lib/python3.7/site-packages (from torchvision->clip==1.0) (1.21.4)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /environment/miniconda3/lib/python3.7/site-packages (from torchvision->clip==1.0) (8.4.0)\n",
      "Building wheels for collected packages: clip\n",
      "  Building wheel for clip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369206 sha256=9ccd9c5b9cf53d189b85b47ad1b4654546fca1e3f36383d600e5a2ce5b3e43ed\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-dz2rjjkn/wheels/fd/b9/c3/5b4470e35ed76e174bff77c92f91da82098d5e35fd5bc8cdac\n",
      "Successfully built clip\n",
      "Installing collected packages: regex, ftfy, clip\n",
      "Successfully installed clip-1.0 ftfy-6.1.1 regex-2022.3.15\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/CLIP.git\n",
    "!pip install ftfy regex tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1047584-30bf-4df3-a680-3d4b07ad6e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set random seed to 2021\n",
      "load checkpoint from local path: checkpoints/stylegan2_c2_ffhq_256_b4x8_20210407_160709-7890ae1f.pth\n",
      "2022-04-10 17:23:47,623 - mmgen - INFO - Switch to evaluation style mode: single\n",
      "2022-04-10 17:23:47,624 - mmgen - INFO - Switch to evaluation style mode: single\n",
      "/environment/miniconda3/lib/python3.7/site-packages/clip/clip.py:53: ResourceWarning: unclosed file <_io.BufferedReader name='/home/featurize/.cache/clip/ViT-B-32.pt'>\n",
      "  if hashlib.sha256(open(download_target, \"rb\").read()).hexdigest() == expected_sha256:\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "2022-04-10 17:23:51,932 - mmgen - INFO - Loading ResNet ArcFace\n",
      "  0%|                                                   | 0/200 [00:00<?, ?it/s]Description: a person with purple hair\n",
      "loss: 0.7881;:   0%|                                    | 0/200 [00:01<?, ?it/s]/environment/miniconda3/lib/python3.7/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "loss: 0.4795;: 100%|██████████████████████████| 200/200 [00:31<00:00,  6.35it/s]\n"
     ]
    }
   ],
   "source": [
    "!python apps/styleclip.py \\\n",
    "        configs/styleganv2/stylegan2_c2_ffhq_256_b4x8_800k.py \\\n",
    "        checkpoints/stylegan2_c2_ffhq_256_b4x8_20210407_160709-7890ae1f.pth \\\n",
    "        --description 'a person with purple hair' \\\n",
    "        --step 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3a4a85e-772d-4837-b948-4d78874d1173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set random seed to 2021\n",
      "load checkpoint from local path: checkpoints/stylegan2_c2_ffhq_256_b4x8_20210407_160709-7890ae1f.pth\n",
      "2022-04-10 18:14:06,671 - mmgen - INFO - Switch to evaluation style mode: single\n",
      "2022-04-10 18:14:06,672 - mmgen - INFO - Switch to evaluation style mode: single\n",
      "/environment/miniconda3/lib/python3.7/site-packages/clip/clip.py:53: ResourceWarning: unclosed file <_io.BufferedReader name='/home/featurize/.cache/clip/ViT-B-32.pt'>\n",
      "  if hashlib.sha256(open(download_target, \"rb\").read()).hexdigest() == expected_sha256:\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "2022-04-10 18:14:10,937 - mmgen - INFO - Loading ResNet ArcFace\n",
      "  0%|                                                   | 0/200 [00:00<?, ?it/s]Description: a person with big nose\n",
      "loss: 0.7695;:   0%|                                    | 0/200 [00:01<?, ?it/s]/environment/miniconda3/lib/python3.7/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "loss: 0.5186;: 100%|██████████████████████████| 200/200 [00:32<00:00,  6.18it/s]\n"
     ]
    }
   ],
   "source": [
    "!python apps/styleclip.py \\\n",
    "        configs/styleganv2/stylegan2_c2_ffhq_256_b4x8_800k.py \\\n",
    "        checkpoints/stylegan2_c2_ffhq_256_b4x8_20210407_160709-7890ae1f.pth \\\n",
    "        --description 'a person with big nose' \\\n",
    "        --step 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7202effe-8585-48a3-9156-19c7b4cdecef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set random seed to 2021\n",
      "load checkpoint from local path: checkpoints/stylegan2_c2_ffhq_256_b4x8_20210407_160709-7890ae1f.pth\n",
      "2022-04-10 18:26:32,950 - mmgen - INFO - Switch to evaluation style mode: single\n",
      "2022-04-10 18:26:32,951 - mmgen - INFO - Switch to evaluation style mode: single\n",
      "/environment/miniconda3/lib/python3.7/site-packages/clip/clip.py:53: ResourceWarning: unclosed file <_io.BufferedReader name='/home/featurize/.cache/clip/ViT-B-32.pt'>\n",
      "  if hashlib.sha256(open(download_target, \"rb\").read()).hexdigest() == expected_sha256:\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "2022-04-10 18:26:37,111 - mmgen - INFO - Loading ResNet ArcFace\n",
      "  0%|                                                   | 0/200 [00:00<?, ?it/s]Description: a person with small mouth\n"
     ]
    }
   ],
   "source": [
    "!python apps/styleclip.py \\\n",
    "        configs/styleganv2/stylegan2_c2_ffhq_256_b4x8_800k.py \\\n",
    "        checkpoints/stylegan2_c2_ffhq_256_b4x8_20210407_160709-7890ae1f.pth \\\n",
    "        --description 'a person with small mouth' \\\n",
    "        --step 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf68580-6989-4f87-8ec8-642d6b60e40a",
   "metadata": {},
   "source": [
    "### 图像变 GIF 动图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f58cbb7-7029-4cc0-a8ca-173b052055e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 294.13it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.chdir('work_dirs/styleclip')\n",
    "img_array = []\n",
    "for filename in tqdm(os.listdir()):\n",
    "    try:\n",
    "        img = cv2.imread(filename)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "        img_array.append(img)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "out = cv2.VideoWriter('../text2img.mp4',cv2.VideoWriter_fourcc(*'mp4v'), 15, size)\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()\n",
    "\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8797d5cf-bb21-401b-ba47-fa4983c70d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27df1329-532b-4ec9-bda7-f45f6cd878f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e38bc573-548d-4198-9933-98f93ae591ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set random seed to 2021\n",
      "load checkpoint from local path: checkpoints/stylegan2_c2_ffhq_256_b4x8_20210407_160709-7890ae1f.pth\n",
      "2022-04-10 18:22:43,054 - mmgen - INFO - Sampling model: ema\n",
      "2022-04-10 18:22:43,054 - mmgen - INFO - Show mode: sequence\n",
      "2022-04-10 18:22:43,054 - mmgen - INFO - Samples path: None\n",
      "2022-04-10 18:22:43,054 - mmgen - INFO - Switch to evaluation style mode: single\n",
      "2022-04-10 18:22:49,487 - mmgen - INFO - Load projected latent: work_dirs/project_result.pt\n",
      "Traceback (most recent call last):\n",
      "  File \"apps/interpolate_sample.py\", line 374, in <module>\n",
      "    main()\n",
      "  File \"apps/interpolate_sample.py\", line 273, in main\n",
      "    proj_file = torch.load(args.proj_latent)\n",
      "  File \"/environment/miniconda3/lib/python3.7/site-packages/torch/serialization.py\", line 594, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/environment/miniconda3/lib/python3.7/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/environment/miniconda3/lib/python3.7/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'work_dirs/project_result.pt'\n"
     ]
    }
   ],
   "source": [
    "!python apps/interpolate_sample.py \\\n",
    "        configs/styleganv2/stylegan2_c2_ffhq_256_b4x8_800k.py \\\n",
    "        checkpoints/stylegan2_c2_ffhq_256_b4x8_20210407_160709-7890ae1f.pth \\\n",
    "        --proj-latent \\\n",
    "        work_dirs/project_result.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f07a4f-609f-4e31-a6af-8faf57d3b4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python apps/interpolate_sample.py \\\n",
    "        configs/styleganv2/stylegan2_c2_ffhq_256_b4x8_800k.py \\\n",
    "        checkpoints/stylegan2_c2_ffhq_256_b4x8_20210407_160709-7890ae1f.pth \\\n",
    "        --proj-latent \\\n",
    "        work_dirs/project_result.pt \\\n",
    "        --samples-path work_dirs/inter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
